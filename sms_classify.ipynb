{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for SMS spam classification\n",
    "\n",
    "\n",
    "Each line of the data file `sms.txt`\n",
    "contains a label---either \"spam\" or \"ham\" (i.e. non-spam)---followed\n",
    "by a text message. Here are a few examples (line breaks added for readability):\n",
    "\n",
    "    ham     Ok lar... Joking wif u oni...\n",
    "    ham     Nah I don't think he goes to usf, he lives around here though\n",
    "    spam    Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.\n",
    "            Text FA to 87121 to receive entry question(std txt rate)\n",
    "            T&C's apply 08452810075over18's\n",
    "    spam    WINNER!! As a valued network customer you have been\n",
    "            selected to receivea £900 prize reward! To claim\n",
    "            call 09061701461. Claim code KL341. Valid 12 hours only.\n",
    "\n",
    "To create features suitable for logistic regression, use tools from the ``sklearn.feature_extraction.text``:\n",
    "\n",
    "* Convert words to lowercase.\n",
    "* Remove punctuation and special characters (but convert the \\$ and\n",
    "  £ symbols to special tokens and keep them, because these are useful for predicting spam).\n",
    "* Create a dictionary containing the 3000 words that appeared\n",
    "  most frequently in the entire set of messages.\n",
    "* Encode each message as a vector $\\mathbf{x}^{(i)} \\in\n",
    "  \\mathbb{R}^{3000}$. The entry $x^{(i)}_j$ is equal to the\n",
    "  number of times the $j$th word in the dictionary appears in that\n",
    "  message.\n",
    "* Discard some ham messages to have an\n",
    "  equal number of spam and ham messages.\n",
    "* Split data into a training set of 1000 messages and a\n",
    "  test set of 400 messages.\n",
    "  \n",
    "Follow the instructions below to complete the implementation. You will be asked to: \n",
    "\n",
    "* write a code to implement logestic regression algorithm (you can use sklearn library for this but it affects your score.)\n",
    "* Make predictions and report the accuracy on the test set\n",
    "* Test out the classifier on a few of your own text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Logisitc Regression classifier\n",
    "for this part you can use Andrew Ng course for machine learning week3 in coursera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prep data\n",
    "using provided construction load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='./sms.txt'\n",
    "with open(path) as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[] ; feature=[]\n",
    "for l in lines: target.append(l[:3]) ; feature.append(l[4:len(l)-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni..</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature target\n",
       "0  Go until jurong point, crazy.. Available only ...    ham\n",
       "1                       Ok lar... Joking wif u oni..    ham"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(feature,target),columns=['feature','target'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature'] = df['feature'].str.replace('\\d+', '')\n",
    "df['feature'] = df['feature'].str.lower()\n",
    "df['feature'] = df['feature'].str.replace(r'[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "data = vectorizer.fit_transform(df['feature'])\n",
    "#vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train logistic regresion model\n",
    "Using the logestic Regression method, train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on test set\n",
    "Use the model fit in the previous cell to make predictions on the test set and compute the accuracy (percentage of messages in the test set that are classified correctly). You should be able to get accuracy above 95%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect model parameters\n",
    "find which words are most common in spam and ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make a prediction on new messages\n",
    "Type a few of your own messages in below and make predictions. Are they ham or spam? Do the predictions make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3194)\t0.2925489569980067\n",
      "  (0, 6982)\t0.22034179063014236\n",
      "  (0, 5146)\t0.31809939238015034\n",
      "  (0, 5038)\t0.2053760358865043\n",
      "  (0, 6033)\t0.1510056744887204\n",
      "  (0, 5294)\t0.31809939238015034\n",
      "  (0, 2887)\t0.17178929067253457\n",
      "  (0, 1251)\t0.32578479081429085\n",
      "  (0, 3939)\t0.22707067827539176\n",
      "  (0, 4802)\t0.19548811471828356\n",
      "  (0, 3491)\t0.12225693876694367\n",
      "  (0, 1688)\t0.2425713765968942\n",
      "  (0, 811)\t0.2145406383109565\n",
      "  (0, 1550)\t0.1417063587391772\n",
      "  (0, 7223)\t0.31685024517647237\n",
      "  (0, 6845)\t0.3644091832327992\n",
      "  (1, 2686)\t0.2763568694085726\n",
      "  (1, 4733)\t0.1270308219072053\n",
      "  (1, 3607)\t0.12037903388605233\n",
      "  (1, 3008)\t0.18769507324999662\n",
      "  (1, 4385)\t0.2059706807268583\n",
      "  (1, 7083)\t0.1659985388362787\n",
      "  (1, 4743)\t0.1577680482224013\n",
      "  (1, 2341)\t0.3080332263777975\n",
      "  (1, 6419)\t0.24318490703404466\n",
      "  :\t:\n",
      "  (4177, 7253)\t0.12851619435128098\n",
      "  (4177, 1572)\t0.11836095234262708\n",
      "  (4177, 6553)\t0.28460868748890367\n",
      "  (4177, 6532)\t0.11486300667798416\n",
      "  (4177, 3607)\t0.1084257181473214\n",
      "  (4177, 6536)\t0.08985844883450542\n",
      "  (4177, 6033)\t0.24125452552811238\n",
      "  (4178, 5486)\t0.3122365189998179\n",
      "  (4178, 7418)\t0.29853793494452663\n",
      "  (4178, 329)\t0.27981232237604575\n",
      "  (4178, 241)\t0.2512801033982091\n",
      "  (4178, 4773)\t0.1583878756892055\n",
      "  (4178, 3125)\t0.24874902444809469\n",
      "  (4178, 1746)\t0.21372976316661577\n",
      "  (4178, 5202)\t0.457062760548959\n",
      "  (4178, 5786)\t0.23516231544166077\n",
      "  (4178, 2039)\t0.2342753575846598\n",
      "  (4178, 3213)\t0.14227008773265723\n",
      "  (4178, 7282)\t0.22212047592995152\n",
      "  (4178, 1617)\t0.22415310281331896\n",
      "  (4178, 7408)\t0.0973131218230351\n",
      "  (4178, 4733)\t0.14616363212959138\n",
      "  (4178, 6655)\t0.09405782234367725\n",
      "  (4178, 4802)\t0.19949009107078355\n",
      "  (4178, 1550)\t0.14460733048106708\n",
      "['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('/Users/apple/Documents/SBU/Mine/SMSSpamCollection', delimiter='\\t',header=None)\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1],df[0])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "print(X_train)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "X_test = vectorizer.transform( ['URGENT! Your Mobile No 1234 was awarded a Prize', 'Hey honey, whats up?'] )\n",
    "predictions = classifier.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7535 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56076 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
